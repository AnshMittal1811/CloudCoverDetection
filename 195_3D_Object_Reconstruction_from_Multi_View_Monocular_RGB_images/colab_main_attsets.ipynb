{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_main_attsets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajithbalakrishnan/3D-Model-Reconstruction/blob/wipropc/colab_main_attsets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQD-oqcceJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajithbalakrishnan/3D-Model-Reconstruction/blob/wipropc/colab_main_attsets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpWbJJ4c9m4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd 3D-Model-Reconstruction/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghSM9zHXJhrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip 02828884.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJQBU6rxBsRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install keras==2.2.4\n",
        "#!pip install pycollada==0.6\n",
        "!pip install pymcubes==0.0.9    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goO7LQkROpCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras tensorflow scipy pandas numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmqG3U40PR6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Ajithbalakrishnan/3D-Model-Reconstruction.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9burQR2bZijh",
        "colab_type": "code",
        "outputId": "97e70ca0-47ac-4dc7-efe1-dbb1d13163a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import scipy.io\n",
        "sys.path.append('..')\n",
        "import tools as tools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from keras.layers import BatchNormalization,Conv3D,MaxPooling3D,Dense,Reshape,Add,LeakyReLU,Conv3DTranspose,Input, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Activation, Concatenate, Lambda,Conv2D\n",
        "from keras.activations import relu,sigmoid,tanh\n",
        "from keras import models\n",
        "import copy \n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbPdKyxoMWI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpB1i-x-ZyfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2\n",
        "img_res = 127\n",
        "vox_res32 = 32\n",
        "total_mv = 24   \n",
        "GPU0 = '0'\n",
        "GPU1 = '0'\n",
        "\n",
        "re_train=False\n",
        "#re_train=True             ##############################\n",
        "single_view_train = True\n",
        "multi_view_train = True\n",
        "\n",
        "#####################################\n",
        "\n",
        "config={}                                 # python dictionary\n",
        "config['batch_size'] = batch_size\n",
        "config['total_mv'] = total_mv\n",
        "config['cat_names'] = ['02933112','04256520']\n",
        "#config['cat_names'] = ['02691156','02828884','02933112','02958343','03001627','03211117',\n",
        "#            '03636649','03691459','04090263','04256520','04379243','04401088','04530566']\n",
        "#config['cat_names'] = ['02828884']\n",
        "for name in config['cat_names']:\n",
        " #content/drive/My Drive/Colab Notebooks/3D-Model-Reconstruction/Data_sample_new/ShapeNetRendering\n",
        "    config['X_rgb_'+name] = '/content/drive/My Drive/Colab Notebooks/3D-Model-Reconstruction/Data_sample_new/ShapeNetRendering/'+name+'/'\n",
        "    config['Y_vox_'+name] = '/content/drive/My Drive/Colab Notebooks/3D-Model-Reconstruction/Data_sample_new/ShapeNetVox32/'+name+'/'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1gC57ZNXFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x,numfilt,filtsz,stride_=1,pad='same',act=True,name=None):\n",
        "    x = Conv2D(filters=numfilt, kernel_size=filtsz,strides=stride_,padding=pad,data_format='channels_last',use_bias=False,name=name+'conv2d')(x)\n",
        "    x = BatchNormalization(axis=3,scale=False,name=name+'conv2d'+'bn')(x)\n",
        "    if act:\n",
        "        x = Activation('relu',name=name+'conv2d'+'act')(x)\n",
        "    return x\n",
        "\n",
        "def incresA(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,32,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,32,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,32,3,1,pad,True,name=name+'b1_2')\n",
        "    branch2 = conv2d(x,32,1,1,pad,True,name=name+'b2_1')\n",
        "    branch2 = conv2d(branch2,48,3,1,pad,True,name=name+'b2_2')\n",
        "    branch2 = conv2d(branch2,64,3,1,pad,True,name=name+'b2_3')\n",
        "    branches = [branch0,branch1,branch2]\n",
        "    mixed = Concatenate(axis=3, name=name + '_concat')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,384,1,1,pad,False,name=name+'filt_exp_1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_scaling')([x, filt_exp_1x1])\n",
        "    return final_lay\n",
        "    \n",
        "def incresB(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,192,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,128,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,160,[1,7],1,pad,True,name=name+'b1_2')\n",
        "    branch1 = conv2d(branch1,192,[7,1],1,pad,True,name=name+'b1_3')\n",
        "    branches = [branch0,branch1]\n",
        "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,1152,1,1,pad,False,name=name+'filt_exp_1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_scaling')([x, filt_exp_1x1])\n",
        "    return final_lay\n",
        "    \n",
        "def incresC(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,192,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,192,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,224,[1,3],1,pad,True,name=name+'b1_2')\n",
        "    branch1 = conv2d(branch1,256,[3,1],1,pad,True,name=name+'b1_3')\n",
        "    branches = [branch0,branch1]\n",
        "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,2048,1,1,pad,False,name=name+'fin1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_saling')([x, filt_exp_1x1])\n",
        "    return final_lay\n",
        "    \n",
        "def stemblock(img_input):\n",
        "\tx = conv2d(img_input,32,3,2,'valid',True,name='conv1')\n",
        "\tx = conv2d(x,32,3,1,'valid',True,name='conv2')\n",
        "\tx = conv2d(x,64,3,1,'valid',True,name='conv3')\n",
        "\n",
        "\tx_11 = MaxPooling2D(3,strides=1,padding='valid',name='stem_br_11'+'_maxpool_1')(x)\n",
        "\tx_12 = conv2d(x,64,3,1,'valid',True,name='stem_br_12')\n",
        "\n",
        "\tx = Concatenate(axis=3, name = 'stem_concat_1')([x_11,x_12])\n",
        "\n",
        "\tx_21 = conv2d(x,64,1,1,'same',True,name='stem_br_211')\n",
        "\tx_21 = conv2d(x_21,64,[1,7],1,'same',True,name='stem_br_212')\n",
        "\tx_21 = conv2d(x_21,64,[7,1],1,'same',True,name='stem_br_213')\n",
        "\tx_21 = conv2d(x_21,96,3,1,'valid',True,name='stem_br_214')\n",
        "\n",
        "\tx_22 = conv2d(x,64,1,1,'same',True,name='stem_br_221')\n",
        "\tx_22 = conv2d(x_22,96,3,1,'valid',True,name='stem_br_222')\n",
        "\n",
        "\tx = Concatenate(axis=3, name = 'stem_concat_2')([x_21,x_22])\n",
        "\n",
        "\tx_31 = conv2d(x,192,3,1,'valid',True,name='stem_br_31')\n",
        "\tx_32 = MaxPooling2D(3,strides=1,padding='valid',name='stem_br_32'+'_maxpool_2')(x)\n",
        "\tx = Concatenate(axis=3, name = 'stem_concat_3')([x_31,x_32])\n",
        "\treturn(x)\n",
        "\n",
        "def inceptionresnet2(x):\n",
        "\t#Inception-ResNet-A modules\n",
        "\tx = incresA(x,0.15,name='incresA_1')\n",
        "\tx = incresA(x,0.15,name='incresA_2')\n",
        "\tx = incresA(x,0.15,name='incresA_3')\n",
        "\tx = incresA(x,0.15,name='incresA_4')\n",
        "\tprint(\"A modules\",x.shape)\n",
        "\n",
        "\t#35 × 35 to 17 × 17 reduction module.\n",
        "\tx_red_11 = MaxPooling2D(3,strides=2,padding='valid',name='red_maxpool_1')(x)\n",
        "\n",
        "\tx_red_12 = conv2d(x,384,3,2,'valid',True,name='x_red1_c1')\n",
        "\n",
        "\tx_red_13 = conv2d(x,256,1,1,'same',True,name='x_red1_c2_1')\n",
        "\tx_red_13 = conv2d(x_red_13,256,3,1,'same',True,name='x_red1_c2_2')\n",
        "\tx_red_13 = conv2d(x_red_13,384,3,2,'valid',True,name='x_red1_c2_3')\n",
        "\n",
        "\tx = Concatenate(axis=3, name='red_concat_1')([x_red_11,x_red_12,x_red_13])\n",
        "\tprint(\"1st reduction modules\",x.shape)\n",
        "\n",
        "\t#Inception-ResNet-B modules\n",
        "\tx = incresB(x,0.1,name='incresB_1')\n",
        "\tx = incresB(x,0.1,name='incresB_2')\n",
        "\tx = incresB(x,0.1,name='incresB_3')\n",
        "\tx = incresB(x,0.1,name='incresB_4')\n",
        "\tx = incresB(x,0.1,name='incresB_5')\n",
        "\tx = incresB(x,0.1,name='incresB_6')\n",
        "\tx = incresB(x,0.1,name='incresB_7')\n",
        "\tprint(\"B modules\",x.shape)\n",
        "\n",
        "\t#17 × 17 to 8 × 8 reduction module.\n",
        "\tx_red_21 = MaxPooling2D(3,strides=2,padding='valid',name='red_maxpool_2')(x)\n",
        "\n",
        "\tx_red_22 = conv2d(x,256,1,1,'same',True,name='x_red2_c11')\n",
        "\tx_red_22 = conv2d(x_red_22,384,3,2,'valid',True,name='x_red2_c12')\n",
        "\n",
        "\tx_red_23 = conv2d(x,256,1,1,'same',True,name='x_red2_c21')\n",
        "\tx_red_23 = conv2d(x_red_23,256,3,2,'valid',True,name='x_red2_c22')\n",
        "\n",
        "\tx_red_24 = conv2d(x,256,1,1,'same',True,name='x_red2_c31')\n",
        "\tx_red_24 = conv2d(x_red_24,256,3,1,'same',True,name='x_red2_c32')\n",
        "\tx_red_24 = conv2d(x_red_24,256,3,2,'valid',True,name='x_red2_c33')\n",
        "\n",
        "\tx = Concatenate(axis=3, name='red_concat_2')([x_red_21,x_red_22,x_red_23,x_red_24])\n",
        "\tprint(\"2nd reduction modules\",x.shape)\n",
        "\n",
        "\t#Inception-ResNet-C modules\n",
        "\tx = incresC(x,0.2,name='incresC_1')\n",
        "\tx = incresC(x,0.2,name='incresC_2')\n",
        "\tx = incresC(x,0.2,name='incresC_3')\n",
        "\tprint(\"C modules\",x.shape)\n",
        "\n",
        "\t#TOP\n",
        "\tx = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "\tprint(\"avg_pool\",x.shape)\n",
        "\tx = Dropout(0.8)(x)\n",
        "\tx = Dense(4096, activation='softmax')(x)\n",
        "\treturn(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxLR8IjaA-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_voxel_prediction(prediction, gt):\n",
        "  #\"\"\"  The prediction and gt are 3 dim voxels. Each voxel has values 1 or 0\"\"\"\n",
        "    prediction[prediction >= 0.5] = 1\n",
        "    prediction[prediction < 0.5] = 0        \n",
        "    intersection = np.sum(np.logical_and(prediction,gt))\n",
        "    union = np.sum(np.logical_or(prediction,gt))\n",
        "    IoU = float(intersection) / float(union)\n",
        "    return IoU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9pnPOzaCQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def refiner_network(volumes_in):\n",
        "    with tf.device('/gpu:' + GPU1):\n",
        "        with tf.variable_scope('ref_enc'):\n",
        "\t\n",
        "            input_volumes_32 = tf.reshape(volumes_in, [-1, vox_res32, vox_res32, vox_res32, 1],name=\"ref_net_in\")\n",
        "\t\n",
        "            print(\"input_volumes_32_shape\" , input_volumes_32.shape)   #input_volumes_32_shape (?,32,32,32,1)\n",
        "\t\n",
        "            rn1=Conv3D(filters=32, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_c1')(input_volumes_32)\n",
        "            rn2=BatchNormalization()(rn1)\n",
        "            rn3=LeakyReLU(alpha=.2)(rn2)\n",
        "            volumes_16_l =MaxPooling3D(pool_size=(2, 2, 2),name='ref_m1')(rn3)\n",
        "\t\n",
        "            print(\"volumes_16_l_shape\" , volumes_16_l.shape)      #volumes_16_l_shape (?,16,16,16,32)\n",
        "\t\n",
        "            rn5=Conv3D(filters=64, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_c2')(volumes_16_l)\n",
        "            rn6=BatchNormalization()(rn5)\n",
        "            rn7=LeakyReLU(alpha=.2)(rn6)\n",
        "            volumes_8_l =MaxPooling3D(pool_size=(2, 2, 2),name='ref_m2')(rn7)\n",
        "\t\t\n",
        "            print(\"volumes_8_l_shape\" ,volumes_8_l.shape)\n",
        "\t\t\n",
        "            rn9=Conv3D(filters=128, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_c3')(volumes_8_l)\n",
        "            rn10=BatchNormalization()(rn9)\n",
        "            rn11=LeakyReLU(alpha=.2)(rn10)\n",
        "            volumes_4_l =MaxPooling3D(pool_size=(2, 2, 2),name='ref_m3')(rn11)\n",
        "\t\t\n",
        "            print(\"volumes_4_l_shape\" , volumes_4_l.shape)\n",
        "\t\t\n",
        "            flatten_features=tf.reshape(volumes_4_l , [-1,8192],name=\"ref_fc1_in\")   \n",
        "        with tf.variable_scope('ref_fc'):\n",
        "\t\t\n",
        "            fc1=Dense(units=2048, activation='relu',name='ref_fc1')(flatten_features)\n",
        "#            fc1=tanh(fc1)\n",
        "            \n",
        "            fc1=relu(fc1, alpha=0.0, max_value=None, threshold=0.0)\n",
        "\t\t\n",
        "            print(\"fc1_shape\",fc1.shape)\n",
        "\t\t\n",
        "            fc2=Dense(units=8192, activation='relu',name='ref_fc2')(fc1)\n",
        "#            fc2=tanh(fc2)\n",
        "            fc2=relu(fc2, alpha=0.0, max_value=None, threshold=0.0)\n",
        "\t\t\n",
        "            print(\"fc2_shape\",fc2.shape)\n",
        "\t\t\t\n",
        "            fc2=tf.reshape(fc2, [-1, 4,4,4,128],name=\"ref_fc2_out\")     \n",
        "\t\t\n",
        "        with tf.variable_scope('ref_Dec'):\n",
        "\t\t\n",
        "            reshaped_1=Add()([fc2,volumes_4_l]) \n",
        "\t\t\n",
        "            print(\"reshaped_1.shape\",reshaped_1.shape)\n",
        "\n",
        "            rn13=Conv3DTranspose(filters=64, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_d1',strides=(2, 2, 2))(reshaped_1)\n",
        "\t\n",
        "            rn14=BatchNormalization()(rn13)\n",
        "            volumes_4_r=relu(rn14, alpha=0.0, max_value=None, threshold=0.0)\n",
        "\t\t\n",
        "            print(\"volumes_4_r_shape\",volumes_4_r.shape)\n",
        "\t\t\n",
        "            reshaped_2=Add() ([volumes_4_r,volumes_8_l]) \n",
        "\t\t\n",
        "            print(\"reshaped_2_shape\",reshaped_2.shape)\n",
        "\n",
        "\t\n",
        "            rn16=Conv3DTranspose(filters=32, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_d2',strides=(2, 2, 2))(reshaped_2)\n",
        "            rn17=BatchNormalization()(rn16)\n",
        "            volumes_8_r =relu(rn17, alpha=0.0, max_value=None, threshold=0.0)\n",
        "\t\t \n",
        "            reshaped_3=Add()([volumes_8_r,volumes_16_l])\n",
        "\t\t\n",
        "            print(\"reshaped_3_shape\",reshaped_3.shape)\n",
        "\t\t\n",
        "\t\n",
        "            rn19=Conv3DTranspose(filters=1, kernel_size=(4, 4, 4), padding='same',data_format=\"channels_last\",name='ref_d3',strides=(2, 2, 2))(volumes_8_r)\n",
        "            print(\"rn19_shape\",rn19.shape)\n",
        "#            volumes_16_r= tf.nn.sigmoid(rn19,name='ref_sigmoid1')\n",
        "#            reshape_4=volumes_16_r                             ####################\n",
        "\n",
        "            reshape_4=Add()([rn19,input_volumes_32])\n",
        "            reshape_4=(reshape_4*0.5)\n",
        "            print(\"reshape_4_5\",reshape_4.shape)\n",
        "            \n",
        "            reshape_4= tf.nn.sigmoid(reshape_4,name='ref_sigmoid1')\n",
        "           \n",
        "\t\t\n",
        "            print(\"reshape_4_sig_shape\",reshape_4.shape)\n",
        "\t\t\n",
        "            reshape_5=tf.reshape(reshape_4, [-1, vox_res32, vox_res32, vox_res32],name=\"ref_out\")\n",
        "\n",
        "            return reshape_5\n",
        "\t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2FM5L7RaHej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attsets_fc(x, out_ele_num):\n",
        "\twith tf.variable_scope('att_fc'):\n",
        "\t\tin_ele_num = tf.shape(x)[1]\n",
        "\t\tin_ele_len = int(x.get_shape()[2])\n",
        "\t\tout_ele_len = in_ele_len    \n",
        "\t\tprint(\"out_ele_len \", out_ele_len)\n",
        "\t\t####################\n",
        "\t\tx_1st = x\n",
        "\t\tx_1st_tp = tf.reshape(x_1st, [-1, in_ele_len],name=\"att_in\")\n",
        "\t\tweights_1st = tools.Ops.fc(x_1st_tp, out_d=out_ele_num*out_ele_len, name=\"att\")\n",
        "\t\t\n",
        "\t\t########## option 1\n",
        "\t\tweights_1st = weights_1st\n",
        "\t\t########## option 2\n",
        "#\t\tweights_1st = tf.nn.tanh(weights_1st)\n",
        "\n",
        "\t\t####################\n",
        "\t\tweights_1st = tf.reshape(weights_1st, [-1, in_ele_num, out_ele_num, out_ele_len],name=\"att_fc_out\")\n",
        "\t\tweights_1st = tf.nn.softmax(weights_1st, 1)\n",
        "\t\tx_1st = tf.tile(x_1st[:,:,None,:], [1,1,out_ele_num,1])\n",
        "\t\tx_1st = x_1st*weights_1st\n",
        "\t\tx_1st = tf.reduce_sum(x_1st, axis=1)\n",
        "\t\tx_1st = tf.reshape(x_1st, [-1, out_ele_num*out_ele_len],name=\"att_out\")       \n",
        "\t\treturn x_1st, weights_1st\n",
        "\n",
        "#####################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93M7HtXZaNy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network:\n",
        "\tdef __init__(self):\n",
        "\t\tself.train_mod_dir = './train_mod/'\n",
        "\t\tself.train_sum_dir = './train_sum/'\n",
        "\t\tself.test_res_dir = './test_res/'\n",
        "\t\tself.test_sum_dir = './test_sum/'\n",
        "\t\t\n",
        "\t\tprint ('re_train : ', re_train)\n",
        "\t\tif os.path.exists(self.test_res_dir):\n",
        "\t\t\tif re_train:\n",
        "\t\t\t\tprint ('test_res_dir and files kept!')\n",
        "\t\t\telse:\n",
        "\t\t\t\tshutil.rmtree(self.test_res_dir)\n",
        "\t\t\t\tos.makedirs(self.test_res_dir)\n",
        "\t\t\t\tprint ('test_res_dir: deleted and then created!')\n",
        "\t\telse:\n",
        "\t\t\tos.makedirs(self.test_res_dir)\n",
        "\t\t\tprint ('test_res_dir: created!')\n",
        "\t\t\n",
        "\t\tif os.path.exists(self.train_mod_dir):\n",
        "\t\t\tif re_train:\n",
        "\t\t\t\tif os.path.exists(self.train_mod_dir + 'model.cptk.data-00000-of-00001'):\n",
        "\t\t\t\t\tprint ('model found! will be reused!')\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprint ('model not found! error!')\n",
        "\t\t\t\t\t#exit()\n",
        "\t\t\telse:\n",
        "\t\t\t\tshutil.rmtree(self.train_mod_dir)\n",
        "\t\t\t\tos.makedirs(self.train_mod_dir)\n",
        "\t\t\t\tprint ('train_mod_dir: deleted and then created!')\n",
        "\t\telse:\n",
        "\t\t\tos.makedirs(self.train_mod_dir)\n",
        "\t\t\tprint ('train_mod_dir: created!')\n",
        "\t\t\n",
        "\t\tif os.path.exists(self.train_sum_dir):\n",
        "\t\t\tif re_train:\n",
        "\t\t\t\tprint ('train_sum_dir and files kept!')\n",
        "\t\t\telse:\n",
        "\t\t\t\tshutil.rmtree(self.train_sum_dir)\n",
        "\t\t\t\tos.makedirs(self.train_sum_dir)\n",
        "\t\t\t\tprint ('train_sum_dir: deleted and then created!')\n",
        "\t\telse:\n",
        "\t\t\tos.makedirs(self.train_sum_dir)\n",
        "\t\t\tprint ('train_sum_dir: created!')\n",
        "\t\t\n",
        "\t\tif os.path.exists(self.test_sum_dir):\n",
        "\t\t\tif re_train:\n",
        "\t\t\t\tprint ('test_sum_dir and files kept!')\n",
        "\t\t\telse:\n",
        "\t\t\t\tshutil.rmtree(self.test_sum_dir)\n",
        "\t\t\t\tos.makedirs(self.test_sum_dir)\n",
        "\t\t\t\tprint ('test_sum_dir: deleted and then created!')\n",
        "\t\telse:\n",
        "\t\t\tos.makedirs(self.test_sum_dir)\n",
        "\t\t\tprint ('test_sum_dir: created!')\n",
        "\n",
        "\tdef base_r2n2(self, X_rgb):\n",
        "\t\twith tf.variable_scope('Encoder'):\n",
        "\t\t\tim_num = tf.shape(X_rgb)[1]\n",
        "\n",
        "\t\t\t[_, _, d1, d2, cc] = X_rgb.get_shape()\n",
        "\t\t\tX_rgb = tf.reshape(X_rgb, [-1, int(d1), int(d2), int(cc)],name=\"en_in\")\n",
        "\t\t\tprint(\"Network Structure\")\n",
        "\t\t\tprint(\"base_r2n2\",X_rgb.shape) #base_r2n2 (?, 127, 127, 3)\n",
        "\t\t\twith tf.variable_scope('en'):\n",
        "\t\t\t\n",
        "\t\t\t    x=stemblock(X_rgb)\n",
        "\t\t\t    l12=inceptionresnet2(x)\n",
        "\t\t\t    print(\"inception_net\",l12.shape)\n",
        "\t\t\t    fc = tools.Ops.xxlu(tools.Ops.fc(l12, out_d=4096, name='en_fc1'), label='lrelu')\n",
        "\t\t\t    print(\"fc1_output_r2n\",fc.shape)#fc1_output_r2n (?, 1024)\n",
        "\t\t\t\n",
        "\t\twith tf.variable_scope('Att_Net'):\t\n",
        "\t\t\t#### use fc attention\n",
        "\t\t\tinput = tf.reshape(fc, [-1, im_num, 4096],name=\"Att_fc_in\")\n",
        "\t\t\tprint(\"att_fc_in_r2n\",input.shape) #att_fc_in_r2n (?, ?, 4096)\n",
        "\t\t\tlatent_3d, weights = attsets_fc(input, out_ele_num=1)\n",
        "\t\t\tprint(\"att_fc_out_r2n\",latent_3d.shape) #att_fc_out_r2n (?, 4096)\n",
        "\t\t\t\n",
        "\t\twith tf.variable_scope('Decoder'):\n",
        "\t\t\t####\n",
        "\t\t\tlatent_3d = tools.Ops.xxlu(tools.Ops.fc(latent_3d, out_d=4*4*4*128, name='de_fc2'), label='lrelu')\n",
        "\t\t\tprint(\"fc3_out_r2n\",latent_3d.shape) #fc3_out_r2n (?, 8192)\n",
        "\t\t\tlatent_3d = tf.reshape(latent_3d, [-1, 4, 4, 4, 128],name=\"de_fc2_out\")\n",
        "\t\t####\n",
        "\n",
        "\t\t\tde_c = [128, 128, 128, 64, 32, 1]\n",
        "\t\t\t\n",
        "\t\t\tprint(\"d1_in_r2n\",latent_3d.shape) #d1_in_r2n (?, 4, 4, 4, 128)\n",
        "\t\t\td1 = tools.Ops.xxlu(tools.Ops.deconv3d(latent_3d, k=3, out_c=de_c[1], str=2, name='de_c1'), label='lrelu')\n",
        "\t\t\tprint(\"d1_out_r2n\",d1.shape) #d1_out_r2n (?, 8, 8, 8, 128)\n",
        "\t\t\td2 = tools.Ops.xxlu(tools.Ops.deconv3d(d1, k=3, out_c=de_c[1], str=1, name='de_c2'), label='lrelu')\n",
        "\t\t\tprint(\"d2_out_r2n\",d2.shape) #d2_out_r2n (?, 8, 8, 8, 128)\n",
        "\t\t\td00 = tools.Ops.deconv3d(latent_3d, k=1, out_c=de_c[1], str=2, name='de_c00')\n",
        "\t\t\tprint(\"d00_out_r2n\",d00.shape)#d00_out_r2n (?, 8, 8, 8, 128)\n",
        "\t\t\td2 = d2 + d00\n",
        "\t\t\tprint(\"d2+d00_out_r2n\",d2.shape)#d2+d00_out_r2n (?, 8, 8, 8, 128)\n",
        "\n",
        "\t\t\td3 = tools.Ops.xxlu(tools.Ops.deconv3d(d2, k=3, out_c=de_c[2], str=2, name='de_c3'), label='lrelu')\n",
        "\t\t\tprint(\"d3_out_r2n\",d3.shape)#d3_out_r2n (?, 16, 16, 16, 128)\n",
        "\t\t\td4 = tools.Ops.xxlu(tools.Ops.deconv3d(d3, k=3, out_c=de_c[2], str=1, name='de_c4'), label='lrelu')\n",
        "\t\t\tprint(\"d4_out_r2n\",d4.shape)#d4_out_r2n (?, 16, 16, 16, 128)\n",
        "\t\t\td22 = tools.Ops.deconv3d(d2, k=1, out_c=de_c[2], str=2, name='de_c22')\n",
        "\t\t\tprint(\"d22_out_r2n\",d22.shape)#d22_out_r2n (?, 16, 16, 16, 128)\n",
        "\t\t\td4 = d4 + d22\n",
        "\t\t\tprint(\"d4+d22_out_r2n\",d4.shape)#d4+d22_out_r2n (?, 16, 16, 16, 128)\n",
        "\n",
        "\t\t\td5 = tools.Ops.xxlu(tools.Ops.deconv3d(d4, k=3, out_c=de_c[3], str=2, name='de_c5'), label='lrelu')\n",
        "\t\t\tprint(\"d5_out_r2n\",d5.shape)#d5_out_r2n (?, 32, 32, 32, 64)\n",
        "\t\t\td6 = tools.Ops.xxlu(tools.Ops.deconv3d(d5, k=3, out_c=de_c[3], str=1, name='de_c6'), label='lrelu')\n",
        "\t\t\tprint(\"d6_out_r2n\",d6.shape)#d6_out_r2n (?, 32, 32, 32, 64)\n",
        "\t\t\td44 = tools.Ops.deconv3d(d4, k=1, out_c=de_c[3], str=2, name='de_c44')\n",
        "\t\t\tprint(\"d44_out_r2n\",d44.shape)#d44_out_r2n (?, 32, 32, 32, 64)\n",
        "\t\t\td6 = d6 + d44\n",
        "\t\t\tprint(\"d6+d44_out_r2n\",d6.shape) #d6+d44_out_r2n (?, 32, 32, 32, 64)\n",
        "\n",
        "\t\t\td7 = tools.Ops.xxlu(tools.Ops.deconv3d(d6, k=3, out_c=de_c[4], str=1, name='de_c7'), label='lrelu')\n",
        "\t\t\tprint(\"d7_out_r2n\",d7.shape) #d7_out_r2n (?, 32, 32, 32, 32)\n",
        "\t\t\td8 = tools.Ops.xxlu(tools.Ops.deconv3d(d7, k=3, out_c=de_c[4], str=1, name='de_c8'), label='lrelu')\n",
        "\t\t\tprint(\"d8_out_r2n\",d8.shape)#d8_out_r2n (?, 32, 32, 32, 32)\n",
        "\t\t\td77 = tools.Ops.xxlu(tools.Ops.deconv3d(d7, k=3, out_c=de_c[4], str=1, name='de_c77'), label='lrelu')\n",
        "\t\t\tprint(\"d77_out_r2n\",d77.shape)#d77_out_r2n (?, 32, 32, 32, 32)\n",
        "\t\t\td8 = d8 + d77\n",
        "\t\t\tprint(\"d8+d77_out_r2n\",d8.shape) #d8+d77_out_r2n (?, 32, 32, 32, 32)\n",
        "\n",
        "\t\t\td11 = tools.Ops.deconv3d(d8, k=3, out_c=de_c[5], str=1, name='de_c9')\n",
        "\t\t\tprint(\"d11_out_r2n\",d11.shape) #d11_out_r2n (?, 32, 32, 32, 1)\n",
        "\t\t\t\n",
        "\t\t\tref_in = tf.reshape(d11, [-1, vox_res32, vox_res32, vox_res32],name=\"ref_in\")     ###\n",
        "\t\t\t\n",
        "\t\t\ty = tf.nn.sigmoid(d11,name='de_sigmoid')\n",
        "\n",
        "\t\t\tatt_o = tf.reshape(y, [-1, vox_res32, vox_res32, vox_res32],name=\"de_out\")\n",
        "\t\t\t\n",
        "\t\t\tprint(\"att_out_shape\",att_o.shape) #att_out_shape (?, 32, 32, 32)\n",
        "\t\t\t\n",
        "\t\twith tf.variable_scope('ref_net'):\n",
        "\t\t\n",
        "\t\t\tref_o=refiner_network(ref_in)\n",
        "\t\t\t\n",
        "\t\t\treturn ref_o,att_o, weights\n",
        "\n",
        "\tdef build_graph(self):\n",
        "\t\timg_res = 127\n",
        "\t\tvox_res = 32\n",
        "\t\tself.X_rgb = tf.placeholder(shape=[None, None, img_res, img_res, 3], dtype=tf.float32)\n",
        "\t\tself.Y_vox = tf.placeholder(shape=[None, vox_res, vox_res, vox_res], dtype=tf.float32)\n",
        "\t\tself.lr = tf.placeholder(tf.float32)\n",
        "\t\tself.refine_lr = tf.placeholder(tf.float32)\n",
        "\t\twith tf.device('/gpu:' + GPU0):\n",
        "\t\t\tself.Y_pred,self.vae_o, self.weights = self.base_r2n2(self.X_rgb)\n",
        "\t\t\ttf.summary.histogram('Attsets_Weights', self.weights)\n",
        "\t\twith tf.device('/gpu:' + GPU1):\t\n",
        "\t\t\t### rec loss\n",
        "\t\t\tprint (\"reached\")\n",
        "\t\t\twith tf.variable_scope('Loss_Fun'):\n",
        "\t\t\t\tY_vox_ = tf.reshape(self.Y_vox, shape=[-1, vox_res ** 3])\n",
        "\t\t\t\tY_pred_ = tf.reshape(self.Y_pred, shape=[-1, vox_res ** 3])\n",
        "\t\t\t\tvae_o_=tf.reshape(self.vae_o, shape=[-1, vox_res ** 3])\n",
        "\t\t\t\n",
        "\t\t\t\tself.vae_loss = tf.reduce_mean(-tf.reduce_mean(Y_vox_ * tf.log(vae_o_ + 1e-8), reduction_indices=[1]) -\n",
        "\t\t\t\t\t\t\t\t\t\t tf.reduce_mean((1 - Y_vox_) * tf.log(1 - vae_o_ + 1e-8),reduction_indices=[1]))\n",
        "\t\t\t\tself.rec_loss = tf.reduce_mean(-tf.reduce_mean(Y_vox_ * tf.log(Y_pred_ + 1e-8), reduction_indices=[1]) -\n",
        "\t\t\t\t\t\t\t\t\t\t tf.reduce_mean((1 - Y_vox_) * tf.log(1 - Y_pred_ + 1e-8),reduction_indices=[1]))\n",
        "\t\t\t\tsum_rec_loss = tf.summary.scalar('rec_loss', self.rec_loss)\n",
        "\t\t\t\tself.sum_merged = sum_rec_loss\n",
        "\t\t\t\ttf.summary.histogram('rec_loss', self.rec_loss)\n",
        "\t\t\t\ttf.summary.scalar(\"vae-loss\",self.vae_loss)\n",
        "\t\t\t\ttf.summary.histogram(\"vae_loss\",self.vae_loss)\n",
        "\t\t\t\tself.mean_loss = tf.div(x=tf.math.add(x=self.vae_loss,y=self.rec_loss,name='add_loss'),y=2,name='mean_loss')\n",
        "\t\t\t\ttf.summary.histogram(\"mean_vae_loss\",self.mean_loss)\n",
        "\t\t\t\ttf.summary.scalar(\"mean_vae_loss\",self.mean_loss)\n",
        "\t\t\t\t\n",
        "\t\t\twith tf.variable_scope('Evaluation_Metric'):\t\t\t    \n",
        "                \t\tgt_vox=Y_vox_\n",
        "                \t\tself.iou_ref = metric_iou(Y_pred_,gt_vox)\n",
        "                \t\ttf.summary.scalar('iou_refiner', self.iou_ref)\n",
        "                \t\ttf.summary.histogram('iou_refiner', self.iou_ref)\n",
        "                \t\tself.iou_vae = metric_iou(vae_o_,gt_vox)\n",
        "                \t\ttf.summary.scalar('iou_vae', self.iou_vae)\n",
        "                \t\ttf.summary.histogram(\"iou_vae\",self.iou_vae)\n",
        "                \t\t\n",
        "\t\t\twith tf.variable_scope('Optimization'):\n",
        "\n",
        "                \t\tbase_en_var = [var for var in tf.trainable_variables() if var.name.startswith('Encoder/en')]\n",
        "                \t\tbase_dec_var = [var for var in tf.trainable_variables() if var.name.startswith('Decoder/de')]\n",
        "                \t\tatt_var = [var for var in tf.trainable_variables() if var.name.startswith('Att_Net/att')]\n",
        "                \t\trefine_var = [var for var in tf.trainable_variables() if var.name.startswith('ref_net/ref')]\n",
        "                \t\tself.refine_optim = tf.train.AdamOptimizer(learning_rate=self.refine_lr).minimize(self.rec_loss, var_list=refine_var)\n",
        "                \t\tself.base_en_optim2 = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.mean_loss, var_list=base_en_var)\n",
        "                \t\tself.base_de_optim2 = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.mean_loss, var_list=base_dec_var)\n",
        "                \t\tself.att_optim2 = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.mean_loss, var_list=att_var)\n",
        "\t\t\t    \t\t\t\t\n",
        "\t\t\n",
        "\t\tprint (\"total weights:\",tools.Ops.variable_count())\n",
        "\t\tself.saver = tf.train.Saver(max_to_keep=1)\n",
        "\t\tconfig = tf.ConfigProto(allow_soft_placement=True)\n",
        "\t\tconfig.gpu_options.allow_growth = True\n",
        "\t\tconfig.gpu_options.visible_device_list = '0'\n",
        "\t\tself.sess = tf.Session(config=config)\n",
        "\t\tself.merged = tf.summary.merge_all()\n",
        "\t\tself.sum_writer_train = tf.summary.FileWriter(self.train_sum_dir, self.sess.graph)\n",
        "\t\tself.sum_writer_test = tf.summary.FileWriter(self.test_sum_dir, self.sess.graph)\n",
        "\n",
        "\t\t#######################\n",
        "\t\tpath = self.train_mod_dir\n",
        "\t\t#path = './Model_released/'  # retrain the released model\n",
        "\n",
        "\t\tif os.path.isfile(path + 'model.cptk.data-00000-of-00001'):\n",
        "\t\t\tprint (\"restoring saved model!\")\n",
        "\t\t\tself.saver.restore(self.sess, path + 'model.cptk')\n",
        "\t\telse:\n",
        "\t\t\tself.sess.run(tf.global_variables_initializer())\n",
        "\t\treturn 0\n",
        "    \n",
        "\tdef train(self, data):\n",
        "\t\tfor epoch in range(0, 250, 1):\n",
        "\t\t\ttrain_view_num = 24  ##!!!!!!!!!!!\n",
        "\t\t\tdata.shuffle_train_files(epoch, train_mv=train_view_num)\n",
        "\t\t\ttotal_train_batch_num = data.total_train_batch_num  #int(len(self.X_rgb_train_files)/(self.batch_size*train_mv))\n",
        "\t\t\tprint ('total_train_batch_num:', total_train_batch_num)\n",
        "\t\t\tfor i in range(total_train_batch_num):\n",
        "\t\t\t\t#### training\n",
        "\t\t\t\tX_rgb_bat, Y_vox_bat = data.load_X_Y_train_next_batch(train_mv=train_view_num)\n",
        "\t\t\t\tprint(\"multi_view_train_X_rgb_bat : \",X_rgb_bat.shape)#np.asarray(X.append(X_rgb[b*train_mv:(b+1)*train_mv,:]))\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\t\tprint(time.ctime())\n",
        "\t\t\t\t\n",
        "\t\t\t\t##### option 1: seperate train, seperate optimize\n",
        "\t\t\t\tif epoch<=30:\n",
        "\t\t\t\t\tsingle_view_train=True\n",
        "\t\t\t\t\tmulti_view_train=False\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsingle_view_train=False\n",
        "\t\t\t\t\tmulti_view_train=True\n",
        "\n",
        "\t\t\t\t##### optiion 2: joint train, seperate optimize\n",
        "\t\t\t\t#single_view_train = True\n",
        "\t\t\t\t#multi_view_train = True\n",
        "\t\t\t\t\n",
        "\t\t\t\tif epoch <= 10:\n",
        "\t\t\t\t\tatt_lr=.001\n",
        "\t\t\t\t\tref_lr=.001\n",
        "\t\t\t\tif epoch > 10 and epoch <= 20:\n",
        "\t\t\t\t\tatt_lr=.0003\n",
        "\t\t\t\t\tref_lr=.0003\n",
        "\t\t\t\tif epoch > 20 :\n",
        "\t\t\t\t\tatt_lr=.0001\n",
        "\n",
        "\t\t\t\t###########  single view train\n",
        "\t\t\t\tif single_view_train:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\trgb = np.reshape(X_rgb_bat,[batch_size*train_view_num, 1, 127,127,3])\n",
        "\t\t\t\t\tprint(\"single_view_train_rgb_input_shape \",rgb.shape)\n",
        "\t\t\t\t\tvox = np.tile(Y_vox_bat[:,None,:,:,:],[1,train_view_num,1,1,1])\n",
        "\t\t\t\t\tvox = np.reshape(vox, [batch_size*train_view_num, 32,32,32])\t\n",
        "\t\t\t\t\tvae_loss_c,eee,ddd, rec_loss_c, sum_train,rrr,mean_vae,iou_ref_,iou_vae_ = self.sess.run([self.vae_loss,self.base_en_optim2,self.base_de_optim2,self.rec_loss,self.merged,self.refine_optim,self.mean_loss,self.iou_ref,self.iou_vae],feed_dict={self.X_rgb: rgb, self.Y_vox: vox, self.lr: att_lr,self.refine_lr: ref_lr})\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train single rec loss:', rec_loss_c)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train single vae loss:', vae_loss_c)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train single mean_vae loss:',mean_vae)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train single ref_iou:',iou_ref_)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train single vae_iou:',iou_vae_)\n",
        "                                        \t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t########## multi view train\n",
        "\t\t\t\tif multi_view_train:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tvae_loss_c,rec_loss_c, _, sum_train,xxx,mean_vae,iou_ref_,iou_vae_ = self.sess.run([self.vae_loss,self.rec_loss, self.att_optim2, self.merged,self.refine_optim,self.mean_loss,self.iou_ref,self.iou_vae],feed_dict={self.X_rgb: X_rgb_bat, self.Y_vox: Y_vox_bat,self.lr: att_lr,self.refine_lr: ref_lr})\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train multi rec loss:', rec_loss_c)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train multi vae loss:', vae_loss_c)\n",
        "\t\t\t\t\tprint('ep:',epoch,'i',i,'train multi mean_vae loss:',mean_vae)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train multi ref_iou:',iou_ref_)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'train multi vae_iou:',iou_vae_)\n",
        "                                        \t\t\t\t\n",
        "\t\t\t\t############\n",
        "\t\t\t\tif i % 10 == 0:\n",
        "\t\t\t\t\tself.sum_writer_train.add_summary(sum_train, epoch * total_train_batch_num + i)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\n",
        "\t\t\t\t#### testing\n",
        "\t\t\t\tif i % 50 == 0 :\n",
        "\t\t\t\t\tX_rgb_batch, Y_vox_batch = data.load_X_Y_test_next_batch(test_mv=3)\n",
        "\t\t\t\t\t\n",
        "#\t\t\t\t\tvae_pred = tf.get_default_graph().get_tensor_by_name(\"Decoder/de_out:0\")\n",
        "#\t\t\t\t\tref_pred = tf.get_default_graph().get_tensor_by_name(\"ref_net/ref_Dec/ref_out:0\")\n",
        "#\t\t\t\t\tgt_vox=Y_vox_batch.astype(np.float32)\n",
        "\t\t\t\t\t\n",
        "#\t\t\t\t\tiou_pred = metric_iou(ref_pred,gt_vox)\n",
        "#\t\t\t\t\ttf.summary.scalar(\"iou\",iou_pred)\n",
        "\n",
        "\t\t\t\t\trrrr,aaaa,rec_loss_te, qwerty, Y_vox_test_pred, att_pred, sum_test,mean_vae,iou_ref_,iou_vae_ = \\\n",
        "\t\t\t\t\t\tself.sess.run([self.refine_optim,self.att_optim2,self.rec_loss,self.vae_loss, self.Y_pred,self.weights, self.merged,self.mean_loss,self.iou_ref,self.iou_vae],feed_dict={self.X_rgb: X_rgb_batch, self.Y_vox: Y_vox_batch,self.lr: att_lr,self.refine_lr: ref_lr})\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\tX_rgb_batch = X_rgb_batch.astype(np.float16)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tY_vox_batch = Y_vox_batch.astype(np.float16)\n",
        "\t\t\t\t\tY_vox_test_pred = Y_vox_test_pred.astype(np.float16)\n",
        "\t\t\t\t\tatt_pred = att_pred.astype(np.float16)\n",
        "\t\t\t\t\tto_save = {'X_test':X_rgb_batch,'Y_test_pred':Y_vox_test_pred,'att_pred':att_pred,'Y_test_true':Y_vox_batch}\n",
        "\t\t\t\t\tscipy.io.savemat(self.test_res_dir+'X_Y_pred_'+str(epoch).zfill(2)+'_'+str(i).zfill(5)+'.mat',to_save,do_compression=True)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tself.sum_writer_test.add_summary(sum_test, epoch * total_train_batch_num + i)\n",
        "\t\t\t\t\t\t\t\t\t\t\n",
        "#\t\t\t\t\tiou_ref=evaluate_voxel_prediction(ref_pred_,gt_vox)\n",
        "#\t\t\t\t\tiou_vae=evaluate_voxel_prediction(vae_pred_,gt_vox)\n",
        "\t\t\t\t\t\n",
        "#\t\t\t\t\tprint(\"Ref_iou:\",iou_ref)\n",
        "#\t\t\t\t\tprint(\"Vae_iou:\",iou_vae)\n",
        "\t\t\t\t\t\n",
        "#\t\t\t\t\tplot_list_iou.append(iou_ref)\n",
        "#\t\t\t\t\tplot_list_i.append((i/50))\n",
        "#\t\t\t\t\tgraph_plot(plot_list_iou,plot_list_i)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'test rec loss:', rec_loss_te)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'test vae loss:', qwerty )\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'test mean_vae loss:', mean_vae) \n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'test ref_iou:',iou_ref_)\n",
        "\t\t\t\t\tprint ('ep:', epoch, 'i:', i, 'test vae_iou:',iou_vae_)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t#### model saving\n",
        "\t\t\t\tif i % 100 == 0 :\n",
        "\t\t\t\t\tself.saver.save( self.sess, save_path=self.train_mod_dir + 'model.cptk' )\n",
        "\t\t\t\t\tprint ( 'epoch:', epoch, 'i:', i, 'model saved!' )\n",
        "#\t\t\t\t\tplt.show()\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\t\t\t\t\t\t\t\n",
        "\n",
        "##########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD9mnMz8alcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ =='__main__':\n",
        "\n",
        "\t\tnet = Network()          #net=object to create instance\n",
        "\n",
        "\t\tprint(\"network compleated\")   ###\n",
        "\n",
        "\t\tnet.build_graph()\n",
        "\t\tprint(\"graph compleated\")\n",
        "                \n",
        "#               sys.exit(). sys.exit()        ###\n",
        "\t\t\n",
        "\t\tdata = tools.Data(config)\n",
        "\t\tprint(\"tools.data compleated\")\n",
        "\n",
        "                \n",
        "\t\tprint('trianing data')\n",
        "\t\t\n",
        "\t\tnet.train(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DFKyUXhckEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}